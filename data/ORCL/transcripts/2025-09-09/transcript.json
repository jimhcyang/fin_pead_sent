{
  "symbol": "ORCL",
  "quarter": 1,
  "year": 2026,
  "date": "2025-09-09 17:00:00",
  "content": "Operator: Hello and thank you for standing by. My name is Tiffany, and I will be your conference operator today. At this time, I would like to welcome everyone to the Oracle Corporation Q1 FY2026 conference call. All lines have been placed on mute to prevent any background noise. After the speaker's remarks, there will be a question and answer session. If you would like to ask a question during that time, simply press star then the number one on your telephone keypad. I would now like to turn the call over to Ken Bond, Head of Investor Relations. Ken, please go ahead.\nKen Bond: Thank you, Tiffany. Good afternoon, everyone, and welcome to Oracle's first quarter fiscal year 2026 earnings conference call. A copy of the press release and financial tables, which include a GAAP to non-GAAP reconciliation and other supplemental financial information, can be viewed and downloaded from our investor relations website. Additionally, a list of many customers who purchased Oracle Cloud Services or went live on Oracle Cloud recently will be available from the investor relations website. On the call today are Chairman and Chief Technology Officer, Lawrence Ellison, and Chief Executive Officer, Safra Catz. A reminder, today's discussion will include forward-looking statements, including predictions, expectations, estimates, or other information that might be considered forward-looking. Throughout today's discussion, we will present some important factors relating to our business, which may potentially affect these forward-looking statements. These forward-looking statements are also subject to risks and uncertainties that may cause actual results to differ materially from statements being made today. As a result, we caution you against placing undue reliance on these forward-looking statements and we encourage you to review our most recent reports, including our 10-K and 10-Q, and any applicable amendments for a complete discussion of these factors and other risks that may affect our future results or the market price of our stock. And finally, we are not obligating ourselves to revise our results or these forward-looking statements in light of new information or future events. Before taking questions, we'll begin with a few prepared remarks. And with that, I'd like to turn the call over to Safra.\nSafra Catz: Thanks, Ken, and good afternoon, everyone. Clearly, we had an amazing start to the year because Oracle has become the go-to place for AI workloads. We have signed significant cloud contracts with the who's who of AI, including OpenAI, xAI, Meta, NVIDIA, AMD, and many others. At the end of Q1, remaining performance obligations or RPO now top $455 billion. This is up 359% from last year and up $317 billion from Q4. Our cloud RPO grew nearly 500% on top of 83% growth last year. Now to the results. Using constant currency growth rates, as you can see, we've made some changes to the face of our income statement to better reflect how we manage the business and so you can understand our cloud business dynamics more directly. So here it goes. Total cloud revenue, that's both apps and infrastructure, was up 27% to $7.2 billion. Cloud infrastructure revenue was $3.3 billion, up 54% on top of the 46% growth reported in Q1 last year. OCI consumption revenue was up 57% and demand continues to dramatically outstrip supply. Cloud database services, which were up 32%, now have annualized revenues of nearly $2.8 billion. Autonomous Database revenue was up 43% on top of the 26% growth reported in Q1 last year. Multi-cloud database revenue, where Oracle regions are embedded in AWS, Azure, and GCP, grew 1529% in Q1. Cloud application revenue was $3.8 billion, up 10%, while our strategic back-office application revenue was $2.4 billion, up 16%. Total software revenue for the quarter was $5.7 billion, down 2%. So all in, total revenues for the quarter were $14.9 billion, up 11% from last year and higher than the 8% growth reported in 17% to $6.2 billion. We have also been on an accelerated journey to adopt AI internally to run more efficiently. I expect our operating income will grow mid-teens this year and higher still in FY2027. Non-GAAP EPS was $1.47 while GAAP EPS was $1.01. The non-GAAP tax rate for the quarter was 20.5%, which was higher than the 19% guidance and caused EPS to be $0.03 lower. For the last four quarters, operating cash flow was up 13% to $21.5 billion and free cash flow was a negative $5.9 billion with $27.4 billion of CapEx. Operating cash flow for Q1 was $8.1 billion while free cash flow was a negative $362 million with CapEx of $8.5 billion. At quarter end, we had $11 billion in cash and marketable securities and short-term deferred revenue balance was $12 billion, up 5%. Over the last ten years, we've reduced the shares outstanding by a third at an average price of $55, which is, at this point, much less than a quarter of our current stock price. This quarter, we repurchased 440,000 shares for a total of $95 million. In addition, we paid out dividends of $5 billion over the last twelve months, and the board of directors again declared a quarterly dividend of $0.50 per share. Given our RPO growth, I now expect fiscal year 2026 CapEx will be around $35 billion. As a reminder, the vast majority of our CapEx investments are for revenue-generating equipment that is going into the data centers and not for land or buildings. As we bring more capacity online, we will convert the large RPO backlog into accelerating revenue and profit growth. Now before I dive into specific Q2 guidance, I'd like to share some of the overarching thoughts on fiscal year 2026 and the coming year. Clearly, it was an excellent quarter, and demand for Oracle Cloud infrastructure continues to build. I expect we will sign additional multibillion-dollar customers and that RPO will likely grow to exceed half a trillion dollars. The enormity of this RPO growth enables us to make a large upward revision to the cloud infrastructure portion of our financial plan. We now expect Oracle Cloud Infrastructure will grow 77% to $18 billion this fiscal year and then increase to $32 billion, $73 billion, $114 billion, and $144 billion over the following four years. Much of this revenue is already booked in our $455 billion RPO number and we are off to a fantastic start this year. Now while much attention is focused on our GPU-related business, our non-GPU infrastructure business continues to grow much faster than our competitors. We are also seeing our industry-specific cloud applications drive customers to our back-office cloud app. And finally, the Oracle database is booming with 34 multi-cloud data centers now live inside of Azure, GCP, and AWS, and we will deliver another 37 data centers for a total of 71. All these trends point to revenue growth going higher. For fiscal year 2026, we remain confident and committed to full-year total revenue growth of 16% in constant currency. Beyond fiscal year 2026, I'm even more confident in our ability to further accelerate our top and bottom line growth rate. As mentioned, we will provide an update on our long-range financial targets at our financial analyst meeting at Oracle AI World in Las Vegas in October. Now let me turn to my guidance for Q2, which I'll review on a non-GAAP basis and assuming currency exchange rates remain the same as they are now. Currency should have a $0.03 positive impact on EPS and a 1% positive effect on revenue depending on rounding. However, the actual currency impact may be different as it was in Q1. Here it goes. Total revenue is expected to grow from 12% to 14% in constant currency and is expected to grow from 14% to percent in US dollars at today's exchange rate. Total cloud revenue is expected to grow from 32% to 36% in constant currency and is expected to grow from 33% to 37% in US dollars. Non-GAAP EPS is expected to grow between 8% to 10% and be between $1.58 and $1.62 in constant currency. Non-GAAP EPS is expected to grow 10% to 12% and be between $1.61 and $1.65 in USD. And lastly, my EPS guidance for Q2 assumes a base tax rate of 19%, however, one-time tax events could cause actual tax rates to vary as they did this quarter. Larry, over to you.\nLawrence Ellison: Thank you, Safra. Eventually, AI will change everything. But right now, AI is fundamentally transforming Oracle and the rest of the computer industry. Though not everyone fully grasped the magnitude of the tsunami that is approaching. Look at our quarterly numbers. Some things are undeniably evident. Several world-class AI companies have chosen Oracle to build large-scale GPU-centric data centers to train their AI models. That's because Oracle builds gigawatt-scale data centers that are faster and more cost-efficient at training AI models than anyone else in the world. Training AI models is a gigantic multi-billion dollar market. It's hard to conceive of a technology market as large as that one. But if you look close, you can find one that's even larger. It's the market for AI inferencing. Millions of customers using those AI models to run businesses and governments. In fact, the AI inferencing market will be much, much larger than the AI training market. AI inferencing will be used to run robotic factories, robotic cars, robotic greenhouses, biomolecular simulations for drug design, interpreting medical diagnostic images and laboratory results, automating laboratories, placing bets in financial markets, automating legal processes, automating financial processes, automating sales processes. AI is going to write, that is, generate, the computer programs called AI agents that will automate your sales and marketing processes. Let me repeat that. AI is going to automatically write the computer programs that will then automate your sales processes and your legal processes and everything else and your factories and so on. Think about it. AI inferencing. It's AI inferencing that will change everything. Oracle is aggressively pursuing the AI market. And we're not doing badly in the AI training market, by the way. The difference seems bigger. Oracle is aggressively pursuing the inferencing market as well as the AI training market. We think we are in a pretty good position to be a winner in the inferencing market because Oracle is by far the world's largest custodian of high-value private enterprise data. With the introduction of our new AI database, we added a very important new way for you to store your data in our database. You can vectorize it. And by vectorizing it, by vectorizing all your data, all your data can be understood by AI models. Then we made it very easy for our customers to directly connect all their databases, all their new Oracle AI databases, and cloud storage OCI cloud storage, to the world's most advanced AI reasoning models. ChatGPT, Gemini, Grok, Lama, all of which are uniquely available in the Oracle Cloud. After you vectorize your data and link it to an LLM, the LLM of your choice, you can then ask any question you can think of. For example, how will the latest tariffs impact next quarter's revenue and profit? You ask that question. The large language model will then apply advanced reasoning to the combination of your private enterprise data plus publicly available data. You get answers to important questions without ever compromising the safety and security of your private data. Again, I'd like you to think about this for a moment. A lot of companies are saying we're big into AI because we're writing agents. Well, guess what? We're writing a bunch of agents too. But when they introduced ChatGPT almost three years ago, what you've got to do is have a conversation and ask questions. You weren't automating some process with an agent. You could ask whatever question you wanted to ask and get a well-reasoned answer with all of the latest and best information and high-quality reasoning to go along with it. Who's offering that to customers? We'll be the first. When we deliberate and demonstrate it at AI World next month. That's what our customers have been asking for ever since the introduction of ChatGPT 3.5, almost three years ago. I wanted to ask questions about anything. And, therefore, you need to understand my enterprise data as well as all the publicly available data. Then you can answer the questions that are most important to me. Well, now they can ask those questions. Back to you, Safra.\nSafra Catz: Thank you, Larry. Tiffany, please poll the audience for questions.\nOperator: At this time, if you would like to ask a question, press star, then the number one on your telephone keypad. To withdraw your question, simply press star 1 again. Your first question comes from the line of John DiFucci with Guggenheim Securities. Please go ahead.\nJohn DiFucci: Thank you for taking my question. Listen. Even I am sort of blown away by what this looks like going forward. And this question, I guess, is sort of purposely open-ended. So Lawrence Ellison and Safra Catz, Oracle's become the de facto standard for AI training workloads, and you make money from it. And you have a lot of faith in that. But, clearly, there's more here than just AI training. I know it's a big part of it. You talked about it. But can you talk about what else, a little more detail about what else is driving these pretty amazing forecasts?\nSafra Catz: Go ahead, Larry. I mean, that you were discovering this.\nLawrence Ellison: Yeah. Well, a lot of people are looking for inferencing capacity. I mean, people are running out of inferencing capacity. I mean, the company that called us, I mentioned it, I think, either last quarter or the quarter before, someone called us, we'll take all the capacity you have that's currently not being used anywhere in the world. We don't care. And I've never gotten a call like that. That's a very unusual call. That was for inferencing, not training. There's a huge amount of demand for inferencing. And if you think about it, in the end, all this money we're spending on training is going to have to be translated into products that are sold, which is all inferencing. And the inferencing market, again, is much larger than the training market. And, yes, we are building like everybody else, we're building agents with our application. But we're doing much more than that. You know, I no one's shown me a ChatGPT 3.5. Again, the three years ago, a little less than three years ago when ChatGPT amazed the world. And you could simply talk to your computer and ask questions and get well-reasoned answers based on the latest and most precise information. As long as you ask those questions about publicly available data. And there's a lot of publicly available data. But if you combine the publicly available data with the enterprise data, which companies really don't want to share, you have to do it in such a way that your private enterprise data stays private yet the large language model can still use it for reasoning so as to answer your question, like, how do the latest tariffs or the latest steel prices or whatever affect my quarterly results? Affect my ability to deliver products, affect my revenue, affect my cost. You know, answer those kinds of questions. To answer those kinds of questions, we have to and we have. We had to change our database, fundamentally change our database so you can vectorize all data. That's the form in which large language models understand information is that after it's been vectorized. And then allowing people to ask any question they want about anything. And that's exactly what we've done. But unless you have a database that is secure and reliable and linked to all of the popular LLMs. And we've done all of that. Unless you have that, and you have you have to tell me who else has that besides Oracle. Unless you have that, this can be very hard for you to deliver a ChatGPT-like experience on top of your data as well as publicly available data. That's a unique value proposition for Oracle. And that's because, again, we're the custodian of all of much more data than any of the application companies. They have their application data. They measure their customers in tens of thousands. We measure our customers in millions of databases. So we think we're better positioned than anybody to take advantage of inferencing. In addition, by the way, aside from just our GPU and all of that, we have become the de facto cloud for many of our customers. Again, they want to put some things in our public cloud or in our competitor public cloud working with the Oracle database. Simultaneously, there are a lot of reasons why they want what's called either a dedicated region or cloud at customer. We give our customers so much choice that they're very unusual for us not to be able to meet a customer's needs in one way or another. And then, of course, we have every piece of the stack. We have the infrastructure, we have the database that you're going to hear a lot about. As really the only reasonable store for data that you want to use AI models again, and then we have all of these applications that are just taking off. So we've we just have a lot of different layers. They're all moving in the same direction, and they all benefit our customers when used together.\nJohn DiFucci: Listen. My dad, let me just go ahead. Go ahead, John. I've got don't mean to cut you're gonna compliment us and interrupted you. What a what a I'm so I apologize for being rude. Listen. I was just gonna say my hat's off to both of you. I have been doing this a really long time, and I tell my old team, pay attention to this. Even those that are not working on Oracle. Because this is a career event happening right now, and it looks it's just amazing. And I guess I'm just really happy for you and congrats on this. Amazing.\nLawrence Ellison: Thanks.\nJohn DiFucci: A lot of work. Keep doing it. Keep doing it.\nLawrence Ellison: It's been a lot of work. And well, let me mention two other things. I think that are actually shocking. We have gotten the entire Oracle cloud, the whole thing, every feature, every function of the Oracle cloud, down to something we can put into a handful of racks, three racks. We call it butterfly. It costs $6 million. So we can give you the we can give you a private version of the Oracle Cloud with every feature, every security feature, every function, everything we do. For $6 million. I think the cost for the other hyperscalers is more than five more than a 100 times that. So we can actually give our customers cloud at customer, the full cloud at customer, and we have companies like Vodafone in I I'm not sure which companies I can name or which companies I can't. We have large companies that are buying basically their own Oracle Cloud region. In fact, multiple Oracle Cloud regions. Because they don't want to have any neighbors in their cloud. They don't want other companies in their cloud. But they want the full cloud. They want to pay as they consume. They want all the features, all the function, all the safety, the security. They don't want to have to buy it. They don't want to have to buy and own the software and the hardware. They want us to maintain it, build the network, supply all of that, and they just want to pay for consumption. We can do that at an entry-level price that's 1% of what our competitors can offer. That's one thing. Another thing. Let me give you one more, and I'll stop there. We also have the most advanced application generator of any company. It's interesting. We're an application company and a cloud infrastructure company. And, therefore, we build applications. And as we build applications, we'd like to be more efficient. And the way to be more efficient is to build AI application generators. And we have been doing that. And the latest applications that we are building we're not building them. They're being generated by AI. And we think we're far, far ahead of any of the other application companies in terms of generating the applications. So that's another very significant advantage we have. And, of course, and it's funny. You know, I made the comment that we don't charge separately for our AI and our applications because our applications are AI. They're entirely AI. The new ones, the new ones that we're building, they're nothing other than a bunch of AI agents that we generate that are linked together with workflow. That's all they are. How do you charge separately for that? That's it. That's every application that we have. But the applications are better, and, hopefully, we'll sell more, and that's the way we'll get paid for them. I got thank you, John, for the very nice compliment. Thank you, Larry. Thank you, Safra.\nSafra Catz: Thank you, John, for all these years following us. So kindly also. Thanks. Great day. Probably time for another question. At this point. Your next question comes from the line of Brad Zelnick with Deutsche Bank. Please go ahead.\nBrad Zelnick: Great. Thanks very much. And I think we're all kind of in shock in a very, very good way. Larry, there's no better evidence of a seismic shift happening in computing than these results that you just put up. And Oracle has in your fifty-year track record of navigating transitions and coming out on top. But as we think about enterprise applications, investors are fairly pessimistic these days, and I'd love to hear your perspective. Where do you see this all going for the industry? Where does the market share go for the companies that don't have the database, that don't have the advantages that you have all the way down to the silicon? Is this maybe an extinction event, you know, curious to hear what you think.\nLawrence Ellison: Well, I think we have substantial advantage because we are an infrastructure company, and we are an application company. There are two things that happen. As an application company, we knew we had to start generating our applications. We just couldn't do it with armies of people anymore. We still need people. Don't get me wrong. But the number of people we need is substantially less. And we can build slash generate much better applications than we can hand build. And we've been working on these AI application generators for some time, and then we're actually using them. But the thing is we're not just building application generators. We're building application generators, and then we're building the applications. Which gives us insights to make the application generator better. It's a huge advantage to be on both sides of that equation. Both being an application builder and a builder of the technology of the application generation technology. The AI, the underlying AI application code generators. That's a huge advantage. Let me give you another advantage, which is often a disadvantage. We're very large. We no longer sell individual discrete applications. We sell suites of applications. We decided to go into the medical business against Epic believing that we could solve much more of the problem. Because we're much bigger than they are. And we're by the way, we're much bigger than Workday. And, or ServiceNow. And we're solving a larger portion of the problem. We're able to do all of ERP then we can add all of CRM. But all the pieces are engineered to fit together. That makes it so much easier for customers to consume. So we think that selling being good at application generation, the underlying technology, makes us better build better applications, enables us to build more applications so we can solve more of the problem. So the customers don't have to do all that system integration across multiple vendors. We can just build a suite where all the pieces are engineered to fit together. I think we have tremendous advantages in the application space. We have tremendous advantages in the AI inferencing space where we can again, what we'll demonstrate at Oracle AI World next month is we've taken all of our customer data, all of it. I want to go into all the details now. But you can ask any question you want to ask. Who's your salesperson? Who's the number one prospect in my territory? What product should I be selling them next? What are the best references for me to use to persuade them to use our product? You can get all of those questions answered for you immediately if you're a salesperson. The engineers can look at which features of Oracle Financials are people making the most errors when they're using those features. What do I have to fix and make easier to use? You just ask the question. Because all of that data is available to AI models. Is there anyone else doing this? Not that I know of. It's a huge advantage for us.\nBrad Zelnick: We look forward to AI World, Larry. Thank you. It's an amazing day for Oracle. It's a remarkable day for the industry. Thanks again, and congrats.\nLawrence Ellison: Thank you. Thank you so much.\nOperator: Next question comes from the line of Derrick Wood with TD Cowen. Please go ahead.\nDerrick Wood: Great. Thanks for taking my question. I'll echo my congratulations on this momentous quarter. Safra, the fact that you delivered over $300 billion of new RPO in Q1, just really amazing to see it's going to require a lot of infrastructure build-out. So could you provide a bit more context on how much CapEx and operational cost structure will be needed to fully service these contracts, how we should think about the ramp of these costs relative to the ramp in revenue over the next few years, and generally, how investors should be thinking about the ROI on the spend?\nSafra Catz: Sure. So first of all, as I mentioned in the prepared remarks and as I've said very clearly beforehand, we do not own the property. We do not own the buildings. What we do own and what we engineer is the equipment, and that's equipment that is optimized for the Oracle Cloud. It has extremely special networking capabilities. It has technical capabilities from Larry and his team that allows us to run these workloads much, much faster. And as a result, it's much cheaper than our competitors. And depending on the workload. Now because of that, what we do is we put in that equipment only when it's time, and, usually, very quickly assuming that our customer accepts it, we're already generating revenue. Right away. The faster they accept the system and that it meets their needs, the faster they start using it. The sooner we have revenue. This is, in some ways, I don't want to call it asset light, from the finance world, but it's assets pretty light. And that is really an advantage for us. I know some of our competitors, they like to own buildings. That's not really our specialty. Our specialty is the unique technology, the unique networking, the storage, the just the whole way we put these systems together. And by the way, they are identical, and very simplified and, again, making it possible for us to be very profitable while still being able to offer our customers an incredibly compelling price. What I have indicated is that CapEx looks like it's going to be about $35 billion for this fiscal year. But because we're monitoring this, we're literally putting it in right when we take possession, and then handing it over to generate revenue right away. So we have a very good line of sight for our capabilities to put this out and to just spend on that CapEx right before it starts generating revenue. But at this point, I'm looking at $35 billion for the year. And I think, I mean, it could be a little higher, but I think and if it is higher, it's good news. Because it means more capacity has been handed to me in terms of floor space. And as you also know, we are embedded in our competitors' clouds, again, all we are responsible for to pay for is in fact our equipment, and that goes right away. And there, we're moving ultimately to 71 data centers embedded in our competitors or flash partners.\nDerrick Wood: Very encouraging to hear.\nLawrence Ellison: Can I let me add a couple of very short things? One is we just turned over a giant data hall to one of our customers. And the acceptance time could have been as long as a couple of months. It was one week. It was one week from the time we, quote, owned officially owned the equipment. And they were testing it to the time they started paying for it. One week. So we have an extraordinary team that's doing an extraordinary job of making sure that we get the equipment working very quickly. And our customer is going to accept it. They want to accept it as fast as possible. Because they want to do the work. They want to train their models. And this one took a huge hall, took one week for acceptance. It was an extraordinary event. The other we are a very large consumer of networking equipment, GPUs, etcetera. Because we are a very large consumer, we are able, I think, to get better financing terms from the vendors than some of their people. So I think we have that going for us as well. I think we're going to do very, very well on the finance side. We have advantages there as well.\nDerrick Wood: Great. Thank you, Larry. Thank you, Safra.\nOperator: Of course. Your next question comes from the line of Mark Moerdler with Bernstein Research. Please go ahead.\nMark Moerdler: Thank you very much, Larry and Safra, and, frankly, team Oracle. Amazing and congratulations. I'd like to focus on the AI training business you've been winning. Could you please explain to us how Oracle can create enough of a differentiated moat to assure this business does not get commoditized and how do you continue to drive strong earnings and free cash flow from the training business even if training slows. I think people really need to understand that.\nLawrence Ellison: Well, I got let me I mean, I could do it in with one sentence. Our networks move data very, very fast. And if we can move data faster than the other people, if we have advantages in our super our GPU super clusters that are performance advantages, if you're paying by the hour, if we're twice as fast, we're half the cost.\nSafra Catz: Yeah. Well, that's tight. Hard to beat that. Impressive.\nMark Moerdler: I agree.\nOperator: Your final question comes from the line of Alex Zukin with Wolfe Research. Please go ahead.\nAlex Zukin: Hey, guys. I really appreciate you squeezing me in. I originally was going to ask you if the new Oracle AI database really opens up the general enterprise inferencing market, and based off your script, it sounds like the answer to that question is hell yes. So I guess my follow-up question would be, how do you see that pacing happening over the course of the next few years? How soon after the introduction of the Oracle AI database would you expect your enterprise customers, your sophisticated customers to really be open to interrogating their enterprise data in this fashion? And how does the current supply constraint environment stand in the way of that demand or is it solving as we speak?\nSafra Catz: I don't know if, Larry, you want to cover it. You covered it in No. We've got it.\nLawrence Ellison: Good. Marks. Go ahead. You got it. Go ahead. Okay. I think who wouldn't want that? I mean, I think everyone says they want to use AI. I mean, every I mean, CEOs, they don't want to use AI. Heads of state, heads of government say they want to use AI. We've never had consumers like that. I mean, we nor historically, we don't deal with CEOs. Now we deal with CEOs. Now we deal with heads of government and heads of state. On this because AI is so important. And letting people have you know, use AI on top of their data. That is what they want to do. But they didn't know how to do it securely. They didn't know how to well, they didn't know how to do it, period. And then one of the big risks was, oh my god. I can't share my JPMorgan Chase can't share all of its data. Goldman Sachs can't share all of its data with OpenAI. They won't do it. So or XAI or LAMA or, you know, Meta. They won't it's got to keep it private. So we've got to keep your private data private. We've got to keep your private data secure. But we have to make it available for inferencing by the latest and best reasoning models from OpenAI and XAI and everyone else. And because we have the database, because we can vectorize all the data in the database, because we have very elaborate security models in our database, in the Oracle database, we can do all that. We can deliver all that. And then what we chose to do was to with the AI database was not only make sure we can vectorize all the data so it can be understood by the AI model, we then bundled it with all of the AI models. That's why we did a deal with Google. That's why we did all of these deals where, you know, Gemini you can get Gemini from the Oracle Cloud. You can get from the Oracle Cloud. You can get from the Oracle Cloud. You get Walmart from the Oracle Cloud. I could go on. So we bundled them together. So it's very easy for our customers to use these large language models on a combination. And that's what they want is a combination of all of the publicly available data and all of their enterprise data. Which allows them to ask and get answered any question they can think of, any question that's important to them. Everyone wants it. I think the demand is going to be insatiable. But we can deliver a lot of databases and a lot of AI across our cloud over the next several years. We're in a good position to do that.\nSafra Catz: And this is going to be one of the reasons that Oracle databases, which are still the bulk of the enterprise market by a lot, are going to finally move into the cloud. Many of them will move in the public cloud using the Oracle AI database, but many and the largest enterprises will want their own either dedicated regions or Oracle Cloud at customer. And, again, they can finally get the benefit of AI for their own data using any LLM that they want because they're all in our cloud too.\nAlex Zukin: It sounds like very high margin AI revenue, guys. Congratulations.\nSafra Catz: Thank you. Thank you. Okay.\nKen Bond: Thanks, Alex. A telephonic replay of this conference call will be available for twenty-four hours on our Investor Relations website. Thank you for joining us today. With that, I'll turn the call back to Tiffany for closing.\nOperator: Ladies and gentlemen, this concludes today's call. Thank you all for joining. You may now disconnect."
}